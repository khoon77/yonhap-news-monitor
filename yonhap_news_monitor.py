#!/usr/bin/env python3
"""
ì—°í•©ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ëª¨ë‹ˆí„°
ì‹œê°„ëŒ€ë³„ í—¤ë“œë¼ì¸ ê¸°ì‚¬ë¥¼ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì•Œë¦¼
"""

import requests
import json
import time
import logging
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
import trafilatura
import re
import hashlib
import os
from telegram_bot import TelegramBot
from utils import setup_logging, save_processed_articles, load_processed_articles

class YonhapNewsMonitor:
    def __init__(self, config):
        self.config = config
        self.telegram_bot = TelegramBot(config)
        self.processed_articles = load_processed_articles()
        self.logger = logging.getLogger(__name__)
        
    def get_yonhap_headlines(self):
        """ì—°í•©ë‰´ìŠ¤ í—¤ë“œë¼ì¸ í˜ì´ì§€ì—ì„œ ê¸°ì‚¬ ìˆ˜ì§‘"""
        try:
            url = "https://www.yna.co.kr/report/headline?site=wholemenu_headline"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            self.logger.info(f"ì—°í•©ë‰´ìŠ¤ í—¤ë“œë¼ì¸ í™•ì¸: {url}")
            
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            articles = []
            
            # í—¤ë“œë¼ì¸ ê¸°ì‚¬ ì¶”ì¶œ
            headline_items = soup.find_all('div', class_='headline-list')
            
            if not headline_items:
                # ë‹¤ë¥¸ êµ¬ì¡° ì‹œë„
                headline_items = soup.find_all('article')
                if not headline_items:
                    headline_items = soup.find_all('div', {'class': re.compile(r'.*item.*|.*news.*|.*article.*')})
            
            for item in headline_items[:10]:  # ìµœëŒ€ 10ê°œ ê¸°ì‚¬
                try:
                    # ì œëª© ì¶”ì¶œ
                    title_elem = item.find('a') or item.find('h2') or item.find('h3')
                    if not title_elem:
                        continue
                        
                    title = title_elem.get_text(strip=True)
                    if not title or len(title) < 10:
                        continue
                    
                    # ë§í¬ ì¶”ì¶œ
                    link = title_elem.get('href', '')
                    if link and not link.startswith('http'):
                        link = 'https://www.yna.co.kr' + link
                    
                    # ì‹œê°„ ì •ë³´ ì¶”ì¶œ
                    time_elem = item.find('time') or item.find('span', {'class': re.compile(r'.*time.*|.*date.*')})
                    published_time = ''
                    if time_elem:
                        published_time = time_elem.get_text(strip=True)
                    
                    if title and link:
                        articles.append({
                            'title': title,
                            'link': link,
                            'published_time': published_time,
                            'source': 'ì—°í•©ë‰´ìŠ¤'
                        })
                        
                except Exception as e:
                    self.logger.warning(f"ê¸°ì‚¬ íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue
            
            # ì¼ë°˜ í…ìŠ¤íŠ¸ì—ì„œ ê¸°ì‚¬ ì¶”ì¶œ (fallback)
            if not articles:
                text_content = trafilatura.extract(response.content)
                if text_content:
                    lines = text_content.split('\n')
                    current_title = None
                    current_link = None
                    
                    for line in lines:
                        line = line.strip()
                        if not line:
                            continue
                            
                        # í—¤ë“œë¼ì¸ íŒ¨í„´ ì°¾ê¸°
                        if '[ì—°í•©ë‰´ìŠ¤ ì´ ì‹œê° í—¤ë“œë¼ì¸]' in line or 'â– ' in line:
                            if current_title and current_link:
                                articles.append({
                                    'title': current_title,
                                    'link': current_link,
                                    'published_time': '',
                                    'source': 'ì—°í•©ë‰´ìŠ¤'
                                })
                            current_title = line.replace('â– ', '').strip()
                            current_link = None
                            
                        elif line.startswith('ì „ë¬¸ë³´ê¸°:') or line.startswith('https://'):
                            current_link = line.replace('ì „ë¬¸ë³´ê¸°:', '').strip()
                            
                        elif 'ì‹œê°' in line and ':' in line:
                            # ì‹œê°„ ì •ë³´
                            pass
            
            self.logger.info(f"ì—°í•©ë‰´ìŠ¤ì—ì„œ {len(articles)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘")
            return articles
            
        except requests.exceptions.RequestException as e:
            self.logger.error(f"ì—°í•©ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
            return []
        except Exception as e:
            self.logger.error(f"ì—°í•©ë‰´ìŠ¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def generate_article_hash(self, article):
        """ê¸°ì‚¬ í•´ì‹œ ìƒì„±"""
        content = f"{article['title']}{article['link']}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def is_processed(self, article_hash):
        """ì´ë¯¸ ì²˜ë¦¬ëœ ê¸°ì‚¬ì¸ì§€ í™•ì¸"""
        return article_hash in self.processed_articles
    
    def filter_new_articles(self, articles):
        """ìƒˆë¡œìš´ ê¸°ì‚¬ë§Œ í•„í„°ë§"""
        new_articles = []
        for article in articles:
            article_hash = self.generate_article_hash(article)
            if not self.is_processed(article_hash):
                new_articles.append(article)
                self.processed_articles[article_hash] = {
                    'title': article['title'],
                    'processed_at': datetime.now().isoformat(),
                    'source': article['source']
                }
        return new_articles
    
    def send_article_notification(self, article):
        """ê°œë³„ ê¸°ì‚¬ í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡"""
        try:
            # ë©”ì‹œì§€ í¬ë§· (ì‹¬í”Œí•˜ê²Œ)
            message = f"ğŸ“° <b>{article['title']}</b>\n\n"
            
            if article.get('published_time'):
                message += f"â° {article['published_time']}\n"
            
            message += f"ğŸ“ {article['source']}\n"
            message += f"ğŸ”— <a href='{article['link']}'>ê¸°ì‚¬ ì½ê¸°</a>"
            
            return self.telegram_bot.send_message(message)
            
        except Exception as e:
            self.logger.error(f"í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
            return False
    
    def monitor_news(self):
        """ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰"""
        try:
            self.logger.info("ì—°í•©ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘...")
            
            # ì—°í•©ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ìˆ˜ì§‘
            articles = self.get_yonhap_headlines()
            
            if not articles:
                self.logger.info("ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ìƒˆë¡œìš´ ê¸°ì‚¬ í•„í„°ë§
            new_articles = self.filter_new_articles(articles)
            
            if not new_articles:
                self.logger.info("ìƒˆë¡œìš´ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            self.logger.info(f"ìƒˆë¡œìš´ ê¸°ì‚¬ {len(new_articles)}ê°œ ë°œê²¬")
            
            # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ì•Œë¦¼ (ìŠ¤íŒ¸ ë°©ì§€)
            max_articles = min(len(new_articles), self.config.get('max_articles_per_run', 5))
            successful_notifications = 0
            
            for article in new_articles[:max_articles]:
                if self.send_article_notification(article):
                    successful_notifications += 1
                    time.sleep(2)  # 2ì´ˆ ê°„ê²©ìœ¼ë¡œ ì „ì†¡
                else:
                    break
            
            self.logger.info(f"í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ: {successful_notifications}/{max_articles}ê°œ ì„±ê³µ")
            
            # ì²˜ë¦¬ëœ ê¸°ì‚¬ ì •ë³´ ì €ì¥
            save_processed_articles(self.processed_articles)
            
            self.logger.info(f"{len(new_articles)}ê°œ ê¸°ì‚¬ ì²˜ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ë¡œê¹… ì„¤ì •
        setup_logging()
        logger = logging.getLogger(__name__)
        
        # ì„¤ì • ë¡œë“œ
        with open('config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # ì—°í•©ë‰´ìŠ¤ ëª¨ë‹ˆí„° ì´ˆê¸°í™”
        monitor = YonhapNewsMonitor(config)
        
        # í…”ë ˆê·¸ë¨ ë´‡ ì—°ê²° í…ŒìŠ¤íŠ¸
        if monitor.telegram_bot.test_connection():
            logger.info("âœ… í…”ë ˆê·¸ë¨ ë´‡ ì—°ê²° ì„±ê³µ")
            monitor.telegram_bot.send_message("ğŸ“° ì—°í•©ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ëª¨ë‹ˆí„°ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        else:
            logger.error("âŒ í…”ë ˆê·¸ë¨ ë´‡ ì—°ê²° ì‹¤íŒ¨")
            return
        
        # ë‹¨ì¼ ì‹¤í–‰ (GitHub Actionsìš©)
        monitor.monitor_news()
        
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()